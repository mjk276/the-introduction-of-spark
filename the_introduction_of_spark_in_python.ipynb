{
 "metadata": {
  "name": "",
  "signature": "sha256:8f8193905c9e43b390039525b941cb2f397e4c80c4e5aa72d02720d77bc53a6b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "The Introduction of Spark in Python"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Spark could be programmed by Java, Scala, Python and R.\n",
      "\n",
      "Here, we just introduce how to use spark in python on your own computers for practice.\n",
      "\n",
      "More details, please referenced the book -- Learning Spark by Holden Karau, Andy Konwinski, Patrick Wendell, and Matei Zaharia (O'Reilly). Copyright 2015 Databricks, 978-1-449-35862-4."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The first section: a toy example."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We start a word count example as our \"hello world\" in the distributed frameworks."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark import SparkContext"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# initializing spark in python \n",
      "sc = SparkContext('local', 'pyspark')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load data from external storage\n",
      "lines = sc.textFile(\"e:\\\\spark-1.6.0-bin-hadoop2.4\\\\README.md\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check the first 5 lines\n",
      "lines.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[u'# Apache Spark',\n",
        " u'',\n",
        " u'Spark is a fast and general cluster computing system for Big Data. It provides',\n",
        " u'high-level APIs in Scala, Java, Python, and R, and an optimized engine that',\n",
        " u'supports general computation graphs for data analysis. It also supports a']"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the total rows\n",
      "lines.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "95"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split the lines into words\n",
      "words = lines.flatMap(lambda line: line.split(\" \"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# another split method, need process later\n",
      "words_other = lines.map(lambda line: line.split(\" \"))\n",
      "words_other.take(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[[u'#', u'Apache', u'Spark'],\n",
        " [u''],\n",
        " [u'Spark',\n",
        "  u'is',\n",
        "  u'a',\n",
        "  u'fast',\n",
        "  u'and',\n",
        "  u'general',\n",
        "  u'cluster',\n",
        "  u'computing',\n",
        "  u'system',\n",
        "  u'for',\n",
        "  u'Big',\n",
        "  u'Data.',\n",
        "  u'It',\n",
        "  u'provides']]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "u'#'"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words.take(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[u'#',\n",
        " u'Apache',\n",
        " u'Spark',\n",
        " u'',\n",
        " u'Spark',\n",
        " u'is',\n",
        " u'a',\n",
        " u'fast',\n",
        " u'and',\n",
        " u'general']"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words_tuple = words.map(lambda word: (word, 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words_tuple.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "[(u'#', 1), (u'Apache', 1), (u'Spark', 1), (u'', 1), (u'Spark', 1)]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts = words_tuple.reduceByKey(lambda x, y: x + y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# also could use below code to get counts\n",
      "# counts = words_tuple.countByKey()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get word count \n",
      "counts.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[(u'', 67), (u'help', 1), (u'when', 1), (u'Hadoop', 3), (u'\"local\"', 1)]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts.top(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[(u'your', 1), (u'you', 4)]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts.sortByKey(ascending = False).take(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "[(u'your', 1),\n",
        " (u'you', 4),\n",
        " (u'with', 3),\n",
        " (u'will', 1),\n",
        " (u'wiki](https://cwiki.apache.org/confluence/display/SPARK).', 1),\n",
        " (u'which', 2),\n",
        " (u'when', 1),\n",
        " (u'web', 1),\n",
        " (u'way', 1),\n",
        " (u'versions', 1)]"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Every spark program and shell session will work as follows:**\n",
      "\n",
      "```\n",
      "1. Create some input RDDs from external data.\n",
      "2. Transform them to define new RDDs using transformations like filter().\n",
      "3. Ask spark to persist() any intermediate RDDs that will need to be reused.\n",
      "4. Launch actions such as count() and first() to kick off a parallel computation, which is then optimized and executed by spark.\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# explore readme.md file\n",
      "# filter sentences which have the word \"Python\"\n",
      "pythonLines = lines.filter(lambda line: \"Python\" in line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# if you want to reuse an RDD in the multiple actions\n",
      "pythonLines.persist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "PythonRDD[15] at RDD at PythonRDD.scala:43"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pythonLines.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "u'high-level APIs in Scala, Java, Python, and R, and an optimized engine that'"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pythonLines.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The second section: basic RDDs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = [\"a\", \"b\", \"a\", \"c\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# turn to RDDs\n",
      "# parallelize a collection in my driver program\n",
      "# it requires that you have your entire dataset in memory on one machine\n",
      "data_s = sc.parallelize(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check the first line\n",
      "data_s.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "'a'"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check all data\n",
      "# note: must ensure all data could be placed in memory\n",
      "data_s.collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "['a', 'b', 'a', 'c']"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# like table() in R \n",
      "data_s.countByKey()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "defaultdict(<type 'int'>, {'a': 2, 'c': 1, 'b': 1})"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The map() transformation takes in a fuction and applies it to every element in the RDD."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s.map(lambda x: x + x).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "['aa', 'bb', 'aa', 'cc']"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The filter() transformation takes in a function and returns an RDD that only has elements that pass the filter() function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s.filter(lambda x: x != 'b').collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "['a', 'a', 'c']"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# remove duplicates\n",
      "data_s.distinct().collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "['a', 'c', 'b']"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sample an RDD\n",
      "data_s.sample(withReplacement = False, fraction = .5).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "['a']"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# produce an RDD containing elements from both RDDs.\n",
      "data_s.union(sc.parallelize([\"e\", \"f\", \"g\"])).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "['a', 'b', 'a', 'c', 'e', 'f', 'g']"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s.intersection(sc.parallelize([\"a\", \"f\", \"g\"])).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "['a']"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s.subtract(sc.parallelize([\"a\", \"f\", \"g\"])).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "['c', 'b']"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s.cartesian(sc.parallelize([\"e\", \"f\", \"g\"])).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "[('a', 'e'),\n",
        " ('a', 'f'),\n",
        " ('a', 'g'),\n",
        " ('b', 'e'),\n",
        " ('b', 'f'),\n",
        " ('b', 'g'),\n",
        " ('a', 'e'),\n",
        " ('a', 'f'),\n",
        " ('a', 'g'),\n",
        " ('c', 'e'),\n",
        " ('c', 'f'),\n",
        " ('c', 'g')]"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# reduce() is an action.\n",
      "data_s.reduce(lambda x, y: x + y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "'abac'"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The third section: key/value pairs RDDs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# turn to pair RDDs\n",
      "data_s_pair = data_s.map(lambda x: (x, 1))\n",
      "data_s_pair.collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "[('a', 1), ('b', 1), ('a', 1), ('c', 1)]"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# the other method to construct a pair RDDs\n",
      "data2 = [(\"a\", 3), (\"b\", 4), (\"a\", 1)]\n",
      "data2_s_pair = sc.parallelize(data2)\n",
      "data2_s_pair.collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "[('a', 3), ('b', 4), ('a', 1)]"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# return all values associated with the provided key.\n",
      "data_s_pair.lookup('a')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "[1, 1]"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair.lookup('b')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "[1]"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# collect the results as a map to provide easy lookup\n",
      "data_s_pair.collectAsMap()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "{'a': 1, 'b': 1, 'c': 1}"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data2_s_pair.collectAsMap()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "{'a': 1, 'b': 4}"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair.countByKey()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "defaultdict(<type 'int'>, {'a': 2, 'c': 1, 'b': 1})"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair.reduceByKey(lambda x, y: x + y).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "[('a', 2), ('c', 1), ('b', 1)]"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair.groupByKey().collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "[('a', <pyspark.resultiterable.ResultIterable at 0x6df5dd8>),\n",
        " ('c', <pyspark.resultiterable.ResultIterable at 0x6df5630>),\n",
        " ('b', <pyspark.resultiterable.ResultIterable at 0x6df53c8>)]"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair.map(lambda x: x + x).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "[('a', 1, 'a', 1), ('b', 1, 'b', 1), ('a', 1, 'a', 1), ('c', 1, 'c', 1)]"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair.mapValues(lambda x: x + 1).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "[('a', 2), ('b', 2), ('a', 2), ('c', 2)]"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair.keys().collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "['a', 'b', 'a', 'c']"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair.values().collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "[1, 1, 1, 1]"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair.sortByKey().collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "[('a', 1), ('a', 1), ('b', 1), ('c', 1)]"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair.subtractByKey(sc.parallelize([('a', 1)])).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "[('c', 1), ('b', 1)]"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair.join(sc.parallelize([('a', 2)])).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "[('a', (1, 2)), ('a', (1, 2))]"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair_2 = sc.parallelize([('a', 1), ('b', 2), ('c', 3), ('b', 4)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# filter on second element in python\n",
      "data_s_pair_2.filter(lambda keyValue: keyValue[1] <3).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "[('a', 1), ('b', 2)]"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair_2.mapValues(lambda x: (x, 1)).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "[('a', (1, 1)), ('b', (2, 1)), ('c', (3, 1)), ('b', (4, 1))]"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# similar to reduce() on basic RDDs\n",
      "data_s_pair_2.mapValues(lambda x: (x, 1)).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "[('a', (1, 1)), ('c', (3, 1)), ('b', (6, 2))]"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair_2.combineByKey((lambda x: (x, 1)), \n",
      "                           (lambda x, y: (x[0] + y, x[1] + 1)), \n",
      "                           (lambda x, y: (x[0] + y[0], x[1] + y[1]))).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "[('a', (1, 1)), ('c', (3, 1)), ('b', (6, 2))]"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_s_pair_2.sortByKey().collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "[('a', 1), ('b', 2), ('b', 4), ('c', 3)]"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The fourth section: use machine learning with MLlib"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For example, to use MLlib for a text classification task --- identifying spammy emails.\n",
      "\n",
      "You could do several steps:\n",
      "```\n",
      "1. Read raw data into spark as an RDD.\n",
      "2. Use feature extraction module to convert text into numerical features, this will return an RDD of vectors.\n",
      "3. Apply a classification model.\n",
      "4. Predict the new test dataset to evaluate the model.\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.regression import LabeledPoint\n",
      "from pyspark.mllib.feature import HashingTF\n",
      "from pyspark.mllib.classification import LogisticRegressionWithSGD"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read the data \n",
      "spam = sc.textFile(\"e:\\\\spam.txt\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "normal = sc.textFile(\"e:\\\\ham.txt\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf = HashingTF(numFeatures = 10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split the email into words, and each word is mapped to one feature\n",
      "spamFeatures = spam.map(lambda email: tf.transform(email.split(\" \")))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "normalFeatures = normal.map(lambda email: tf.transform(email.split(\" \")))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create LabeledPoint dataset \n",
      "positiveExamples = spamFeatures.map(lambda features: LabeledPoint(1, features))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "negativeExamples = normalFeatures.map(lambda features: LabeledPoint(0, features))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainingData = positiveExamples.union(negativeExamples)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cache since logistic regression is an iterative algorithm\n",
      "trainingData.cache()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "UnionRDD[114] at union at null:-2"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = LogisticRegressionWithSGD.train(trainingData)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# apply the same HashingTF feature transformation to get vectors\n",
      "posTest = tf.transform(\"O M G GET cheap stuff by sending money to ...\".split(\" \"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "negTest = tf.transform(\"Hi Dad, I started studying Spark the other ...\".split(\" \"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Prediction for positive test example: %g\" % model.predict(posTest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Prediction for positive test example: 1\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Prediction for negative test example: %g\" % model.predict(negTest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Prediction for negative test example: 0\n"
       ]
      }
     ],
     "prompt_number": 73
    }
   ],
   "metadata": {}
  }
 ]
}